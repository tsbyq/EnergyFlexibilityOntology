{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the YAML configuration file\n",
    "config_file_path = 'demo_config.yml'  # Replace with actual path\n",
    "\n",
    "# Function to read a YAML file and return a dictionary\n",
    "def read_yaml_config(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config_dict = yaml.safe_load(file)\n",
    "    return config_dict\n",
    "\n",
    "# Reading the configuration file\n",
    "config_data = read_yaml_config(config_file_path)\n",
    "config_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config_data['path_to_dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Baseline (kWh)</th>\n",
       "      <th>Flexible (kWh)</th>\n",
       "      <th>Peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/17/2021 0:00</td>\n",
       "      <td>0.030926</td>\n",
       "      <td>-3.620000e-14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/17/2021 0:01</td>\n",
       "      <td>0.031567</td>\n",
       "      <td>2.610000e-11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/17/2021 0:02</td>\n",
       "      <td>0.031963</td>\n",
       "      <td>2.650000e-11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/17/2021 0:03</td>\n",
       "      <td>0.032306</td>\n",
       "      <td>2.690000e-11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/17/2021 0:04</td>\n",
       "      <td>0.032656</td>\n",
       "      <td>2.720000e-11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>12/21/2021 23:55</td>\n",
       "      <td>0.033474</td>\n",
       "      <td>1.021433e-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>12/21/2021 23:56</td>\n",
       "      <td>0.033610</td>\n",
       "      <td>1.021549e-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>12/21/2021 23:57</td>\n",
       "      <td>0.033553</td>\n",
       "      <td>1.021675e-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>12/21/2021 23:58</td>\n",
       "      <td>0.033582</td>\n",
       "      <td>1.021811e-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>12/21/2021 23:59</td>\n",
       "      <td>0.033645</td>\n",
       "      <td>1.021958e-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime  Baseline (kWh)  Flexible (kWh)   Peak\n",
       "0      12/17/2021 0:00        0.030926   -3.620000e-14  False\n",
       "1      12/17/2021 0:01        0.031567    2.610000e-11  False\n",
       "2      12/17/2021 0:02        0.031963    2.650000e-11  False\n",
       "3      12/17/2021 0:03        0.032306    2.690000e-11  False\n",
       "4      12/17/2021 0:04        0.032656    2.720000e-11  False\n",
       "...                ...             ...             ...    ...\n",
       "7195  12/21/2021 23:55        0.033474    1.021433e-02  False\n",
       "7196  12/21/2021 23:56        0.033610    1.021549e-02  False\n",
       "7197  12/21/2021 23:57        0.033553    1.021675e-02  False\n",
       "7198  12/21/2021 23:58        0.033582    1.021811e-02  False\n",
       "7199  12/21/2021 23:59        0.033645    1.021958e-02  False\n",
       "\n",
       "[7200 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an RDF graph from the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@prefix ns1: <http://example.org/efkpis#> .\\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\\n\\nns1:EvaluationWindow ns1:endTime \"2019-01-02T00:00:00+00:00\"^^xsd:dateTime ;\\n    ns1:startTime \"2019-01-01T00:00:00+00:00\"^^xsd:dateTime .\\n\\nns1:HighLoadEndTimestamp ns1:hasValue \"2019-01-01T13:00:00+00:00\"^^xsd:dateTime .\\n\\nns1:HighLoadStartTimestamp ns1:hasValue \"2019-01-01T12:00:00+00:00\"^^xsd:dateTime .\\n\\nns1:baseline_power_profile ns1:column_identifier \"Baseline (kW)\" ;\\n    ns1:dtype \"float\" ;\\n    ns1:quantity \"power\" ;\\n    ns1:unit \"kW\" .\\n\\nns1:flexible_power_profile ns1:column_identifier \"Flexible (kW)\" ;\\n    ns1:dtype \"float\" ;\\n    ns1:quantity \"power\" ;\\n    ns1:unit \"kW\" .\\n\\nns1:generic_quantity_profile ns1:column_identifier \"Cost ($)\" ;\\n    ns1:dtype \"float\" ;\\n    ns1:quantity \"unknown\" ;\\n    ns1:unit \"unknown\" .\\n\\nns1:timestamps ns1:column_identifier \"Datetime\" ;\\n    ns1:dtype \"datetime\" ;\\n    ns1:quantity \"time\" ;\\n    ns1:unit \"unknown\" .\\n\\n[] ns1:dataReadingMethod \"pandas\" ;\\n    ns1:dataSourceType \"csv\" ;\\n    ns1:pathToDataset \"path/to/energy_cost_data.csv\" .\\n\\n[] ns1:dataReadingMethod \"pandas\" ;\\n    ns1:dataSourceType \"csv\" ;\\n    ns1:pathToDataset \"path/to/baseline_power_data.csv\" .\\n\\n[] ns1:dataReadingMethod \"pandas\" ;\\n    ns1:dataSourceType \"csv\" ;\\n    ns1:pathToDataset \"path/to/flexible_power_data.csv\" .\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rdflib\n",
    "import yaml\n",
    "\n",
    "def create_data_graph_from_config_v2(config_file_path):\n",
    "    # Load the config file\n",
    "    with open(config_file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    # Initialize an RDF graph\n",
    "    g = rdflib.Graph()\n",
    "\n",
    "    # Namespace for your ontology\n",
    "    efkpis = rdflib.Namespace(\"http://example.org/efkpis#\")\n",
    "    xsd = rdflib.Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "\n",
    "    # Evaluation Window\n",
    "    evaluation_window = efkpis.EvaluationWindow\n",
    "    start_time = rdflib.Literal(config['evaluation_window']['start'], datatype=xsd.dateTime)\n",
    "    end_time = rdflib.Literal(config['evaluation_window']['end'], datatype=xsd.dateTime)\n",
    "    g.add((evaluation_window, efkpis.startTime, start_time))\n",
    "    g.add((evaluation_window, efkpis.endTime, end_time))\n",
    "\n",
    "    # Peak Timestamps\n",
    "    for ts in config['peak_timestamps']['values']:\n",
    "        timestamp = rdflib.Literal(ts, datatype=xsd.dateTime)\n",
    "        if ts == config['peak_timestamps']['values'][0]:\n",
    "            g.add((efkpis.HighLoadStartTimestamp, efkpis.hasValue, timestamp))\n",
    "        else:\n",
    "            g.add((efkpis.HighLoadEndTimestamp, efkpis.hasValue, timestamp))\n",
    "\n",
    "    # Data Sources\n",
    "    for data_source in config['data_sources']:\n",
    "        data_source_node = rdflib.BNode()  # Unique identifier for each data source\n",
    "        source_type = rdflib.Literal(data_source['source_type'])\n",
    "        path_to_dataset = rdflib.Literal(data_source['path_to_dataset'])\n",
    "        data_reading_method = rdflib.Literal(data_source['data_reading_method'])\n",
    "\n",
    "        # Add general data source properties\n",
    "        g.add((data_source_node, efkpis.dataSourceType, source_type))\n",
    "        g.add((data_source_node, efkpis.pathToDataset, path_to_dataset))\n",
    "        g.add((data_source_node, efkpis.dataReadingMethod, data_reading_method))\n",
    "\n",
    "        # Add profiles specific to each data source\n",
    "        for key, profile_data in data_source['pandas_parsing_specs'].items():\n",
    "            profile_node = efkpis[key]  # e.g., efkpis:timestamps, efkpis:baseline_power_profile, etc.\n",
    "            for prop, value in profile_data.items():\n",
    "                literal_value = rdflib.Literal(value or \"unknown\")\n",
    "                g.add((profile_node, efkpis[prop], literal_value))\n",
    "\n",
    "    # Return the RDF graph\n",
    "    return g\n",
    "\n",
    "# Example usage\n",
    "data_graph = create_data_graph_from_config_v2('demo_config_v2.yml')\n",
    "\n",
    "# Serialize the graph to view its contents (optional)\n",
    "# print(data_graph.serialize(format='turtle').decode(\"utf-8\"))\n",
    "\n",
    "data_graph.serialize(format='turtle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query evaluation window parameters from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2019-01-01T00:00:00+00:00, End Time: 2019-01-02T00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# SPARQL query to get the evaluation window\n",
    "query = \"\"\"\n",
    "PREFIX efkpis: <http://example.org/efkpis#>\n",
    "\n",
    "SELECT ?startTime ?endTime\n",
    "WHERE {\n",
    "    efkpis:EvaluationWindow efkpis:startTime ?startTime ;\n",
    "                           efkpis:endTime ?endTime .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "qres = data_graph.query(query)\n",
    "\n",
    "# Print results\n",
    "for row in qres:\n",
    "    print(f\"Start Time: {row.startTime}, End Time: {row.endTime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query high load start and end timestamp from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Load Start Timestamp: 2019-01-01T12:00:00+00:00, High Load End Timestamp: 2019-01-01T13:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# SPARQL query to get the high load timestamps\n",
    "query = \"\"\"\n",
    "PREFIX efkpis: <http://example.org/efkpis#>\n",
    "\n",
    "SELECT ?startTimestamp ?endTimestamp\n",
    "WHERE {\n",
    "    efkpis:HighLoadStartTimestamp efkpis:hasValue ?startTimestamp .\n",
    "    efkpis:HighLoadEndTimestamp efkpis:hasValue ?endTimestamp .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "qres = data_graph.query(query)\n",
    "\n",
    "# Print results\n",
    "for row in qres:\n",
    "    print(f\"High Load Start Timestamp: {row.startTimestamp}, High Load End Timestamp: {row.endTimestamp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query load profile data specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile: http://example.org/efkpis#baseline_power_profile, Column Identifier: Baseline (kW), Quantity: power, Data Type: float, Unit: kW, Data Reading Method: pandas, Data Source Type: csv, Path To Dataset: path/to/baseline_power_data.csv\n",
      "Profile: http://example.org/efkpis#baseline_power_profile, Column Identifier: Baseline (kW), Quantity: power, Data Type: float, Unit: kW, Data Reading Method: pandas, Data Source Type: csv, Path To Dataset: path/to/flexible_power_data.csv\n",
      "Profile: http://example.org/efkpis#baseline_power_profile, Column Identifier: Baseline (kW), Quantity: power, Data Type: float, Unit: kW, Data Reading Method: pandas, Data Source Type: csv, Path To Dataset: path/to/energy_cost_data.csv\n",
      "Profile: http://example.org/efkpis#flexible_power_profile, Column Identifier: Flexible (kW), Quantity: power, Data Type: float, Unit: kW, Data Reading Method: pandas, Data Source Type: csv, Path To Dataset: path/to/baseline_power_data.csv\n",
      "Profile: http://example.org/efkpis#flexible_power_profile, Column Identifier: Flexible (kW), Quantity: power, Data Type: float, Unit: kW, Data Reading Method: pandas, Data Source Type: csv, Path To Dataset: path/to/flexible_power_data.csv\n",
      "Profile: http://example.org/efkpis#flexible_power_profile, Column Identifier: Flexible (kW), Quantity: power, Data Type: float, Unit: kW, Data Reading Method: pandas, Data Source Type: csv, Path To Dataset: path/to/energy_cost_data.csv\n",
      "Profile: http://example.org/efkpis#generic_quantity_profile, Column Identifier: Cost ($), Quantity: unknown, Data Type: float, Unit: unknown, Data Reading Method: pandas, Data Source Type: csv, Path To Dataset: path/to/baseline_power_data.csv\n",
      "Profile: http://example.org/efkpis#generic_quantity_profile, Column Identifier: Cost ($), Quantity: unknown, Data Type: float, Unit: unknown, Data Reading Method: pandas, Data Source Type: csv, Path To Dataset: path/to/flexible_power_data.csv\n",
      "Profile: http://example.org/efkpis#generic_quantity_profile, Column Identifier: Cost ($), Quantity: unknown, Data Type: float, Unit: unknown, Data Reading Method: pandas, Data Source Type: csv, Path To Dataset: path/to/energy_cost_data.csv\n",
      "Profile: http://example.org/efkpis#timestamps, Column Identifier: Datetime, Quantity: time, Data Type: datetime, Unit: unknown, Data Reading Method: pandas, Data Source Type: csv, Path To Dataset: path/to/baseline_power_data.csv\n",
      "Profile: http://example.org/efkpis#timestamps, Column Identifier: Datetime, Quantity: time, Data Type: datetime, Unit: unknown, Data Reading Method: pandas, Data Source Type: csv, Path To Dataset: path/to/flexible_power_data.csv\n",
      "Profile: http://example.org/efkpis#timestamps, Column Identifier: Datetime, Quantity: time, Data Type: datetime, Unit: unknown, Data Reading Method: pandas, Data Source Type: csv, Path To Dataset: path/to/energy_cost_data.csv\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "PREFIX ns1: <http://example.org/efkpis#>\n",
    "\n",
    "SELECT ?profile ?columnIdentifier ?quantity ?dtype ?unit ?dataReadingMethod ?dataSourceType ?pathToDataset\n",
    "WHERE {\n",
    "    VALUES ?profile { ns1:baseline_power_profile ns1:flexible_power_profile ns1:generic_quantity_profile ns1:timestamps }\n",
    "    ?dataSourceInfo ns1:dataReadingMethod ?dataReadingMethod ;\n",
    "                    ns1:dataSourceType ?dataSourceType ;\n",
    "                    ns1:pathToDataset ?pathToDataset .\n",
    "    ?profile ns1:column_identifier ?columnIdentifier ;\n",
    "             ns1:quantity ?quantity ;\n",
    "             ns1:dtype ?dtype ;\n",
    "             ns1:unit ?unit .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query on the RDF graph\n",
    "qres = data_graph.query(query)\n",
    "\n",
    "# Print results\n",
    "for row in qres:\n",
    "    print(f\"Profile: {row.profile}, Column Identifier: {row.columnIdentifier}, \"\n",
    "          f\"Quantity: {row.quantity}, Data Type: {row.dtype}, Unit: {row.unit}, \"\n",
    "          f\"Data Reading Method: {row.dataReadingMethod}, Data Source Type: {row.dataSourceType}, \"\n",
    "          f\"Path To Dataset: {row.pathToDataset}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JPTR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
